{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fTFf8WYXGfD8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as ureq\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TLW17IK9ZHd",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#DEFAULT ELEMENT FOR RATING TO BE CALLED WHEN INCASE OF HTTP ERROR\n",
    "default = \"\"\"\"<div class=\"rating\">\n",
    "      <span class=\"digit\">0</span>\n",
    "      <span class=\"digit\">.</span>\n",
    "      <span class=\"digit\">0</span>\n",
    "    </div>\"\"\"\n",
    "#NUMBER OF PAGES\n",
    "n = 8\n",
    "movie_titles=[]\n",
    "imax_schedule=[]\n",
    "regular_schedule=[]\n",
    "ratings=[]\n",
    "rating_rough_extracts=[]\n",
    "#LOOPING THROUGH PAGES\n",
    "for i in range(1, n+1):\n",
    "    #IDENTIFYING FIRST PAGE\n",
    "    if (i == 1):\n",
    "        # handle first page\n",
    "        parse_hub=ureq(\"https://www.parsehub.com/sandbox/showtimes\")\n",
    "    #handles subsequent pages     \n",
    "    parse_hub = ureq(\"https://www.parsehub.com/sandbox/showtimes\" + \"?page=%d\" % i)\n",
    "    ph_soup= soup(parse_hub,\"lxml\")\n",
    "    movie_elements= ph_soup.find_all(\"a\",{\"class\":\"title\"})\n",
    "    #looping through lists movie_elements which is made up of lists\n",
    "    for movie_element in movie_elements:\n",
    "      #looping through inner list of movie_elements\n",
    "      for sub_movie_element in movie_element:\n",
    "        #appending movie extracted movie titles in list movie_titles\n",
    "        movie_titles.append(sub_movie_element)\n",
    "    #extracting movie schedules\n",
    "    first_movie_showtime_imax = ph_soup.find_all(\"span\",{\"class\":\"borderbox showtime imax first\"})\n",
    "    other_movie_showtime_imax = ph_soup.find_all(\"span\",{\"class\":\"borderbox showtime imax other\"})\n",
    "    first_movie_showtimes_regular = ph_soup.find_all(\"span\",{\"class\":\"borderbox showtime regular first\"})\n",
    "    other_movie_showtimes_regular = ph_soup.find_all(\"span\",{\"class\":\"borderbox showtime regular other\"})\n",
    "    #adding imax showing time of first movie to a list\n",
    "    imax_showtimes=[first_movie_showtime_imax[0].text]\n",
    "    #looping through imax showing times of other movies and appending to imax_showingtimes\n",
    "    for imax_time in other_movie_showtime_imax:\n",
    "        imax_showtimes.append(imax_time.text)\n",
    "    #looping through imax show times and appending to pre-defined imax_schedule list for final output\n",
    "    for imax_showtime in imax_showtimes:\n",
    "        imax_schedule.append(imax_showtime)\n",
    "    #defining list for regular showing times\n",
    "    reg_times=[]\n",
    "    #appending regular showing times for first movie to reg_times\n",
    "    for first_movie_showtime_regular in first_movie_showtimes_regular:\n",
    "        reg_times.append(first_movie_showtime_regular.text)\n",
    "    #appending regular showing times for other movies to reg_times\n",
    "    for other_movie_showtime_regular in other_movie_showtimes_regular:\n",
    "        reg_times.append(other_movie_showtime_regular.text)\n",
    "    #defining dict \n",
    "    regular_times = {}\n",
    "    #creating auxiliary lists to aid extraction of showing times from multi nested lists\n",
    "    aux1=[]\n",
    "    aux2=[]\n",
    "    #defining iterable indexes  and appending to aux1\n",
    "    for index1 in range(0,len(reg_times)-3,4):\n",
    "        aux1.append(index1)\n",
    "    #defining iterable indexes  and appending to aux2\n",
    "    for index2 in range(4,len(reg_times)+1,4):\n",
    "        aux2.append(index2)\n",
    "    #defining number of iter which is dependent on len of auxilliary lists\n",
    "    for number_iter in range(0,len(aux1)):\n",
    "        #changing number_iter type to int\n",
    "        number_iter_to_string=str(number_iter)\n",
    "        #defining dict keys by merging number_iter\n",
    "        time_values = reg_times[aux1[number_iter]:aux2[number_iter]]\n",
    "        regular_schedule.append(time_values)\n",
    "    individual_movie_links = ph_soup.find_all(\"a\",{\"class\":\"title\"})\n",
    "    for individual_movie_link in individual_movie_links:\n",
    "        #declaring exception\n",
    "        try:\n",
    "            #formatting indvividual movie link\n",
    "            indie_link = \"https://www.parsehub.com/\" + individual_movie_link.get(\"href\").replace(\" \",\"%20\")\n",
    "            movie_html =ureq(indie_link)\n",
    "      #if HTTPError is received replace movie with default(a predefined string)\n",
    "        except HTTPError as e:\n",
    "            movie_html= default\n",
    "        movie_soup = soup(movie_html,\"lxml\")\n",
    "        movies = movie_soup.find_all(\"span\",{\"class\":\"digit\"})\n",
    "        #appending extracts to predefined list\n",
    "        rating_rough_extracts.append(movies)\n",
    "extracts=[]\n",
    "#iterating through nested list to extract values\n",
    "for rating_rough_extract in rating_rough_extracts:\n",
    "    for extract in rating_rough_extract:\n",
    "        extracts.append(extract)\n",
    "#formating values to text,concarenating and converting to float\n",
    "#using iteration\n",
    "for aux3 in range(3,243,3):\n",
    "    integer =extracts[aux3-3].text\n",
    "    decimal =extracts[aux3-2].text\n",
    "    s_integer =extracts[aux3-1].text\n",
    "    digit=integer + decimal+s_integer\n",
    "    digits = float(digit)\n",
    "    ratings.append(digits)\n",
    "#importing pandas lib\n",
    "import pandas as pd\n",
    "#converting extracted lists to dataframe\n",
    "movie_parsehub=pd.DataFrame(\n",
    "    {\n",
    "     'Movie': movie_titles,\n",
    "     'Imax screen time':imax_schedule,\n",
    "     'regular_schedule': regular_schedule,\n",
    "     'movie_rating': ratings\n",
    "    })\n",
    "#splitting regulars_schedule into individual columns\n",
    "regular_screentimes =movie_parsehub['regular_schedule'].apply(pd.Series)\n",
    "regular_screentimes= regular_screentimes.rename(columns = lambda x : 'regular_screentime_' + str(x))\n",
    "#adding new columns to new dataframe\n",
    "final_parsehub =pd.DataFrame(pd.concat([movie_parsehub[:], regular_screentimes[:]], axis=1))\n",
    "#dropping regularschedule column\n",
    "final_parsehub.drop(['regular_schedule'],axis=1,inplace =True)\n",
    "#creating csv file\n",
    "final_parsehub.to_csv('my_parse_movie_scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SCRAPING TRIAL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
